{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, sosfilt, sosfiltfilt, hilbert, resample\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Audio\n",
    "from scipy.io.wavfile import read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def envelope(signal):\n",
    "    # Hilbert transform gives analytic signal whose magnitude = envelope\n",
    "    analytic = hilbert(signal)\n",
    "    return np.abs(analytic)\n",
    "\n",
    "def audio_widget(data, fs):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "        display(Audio(data, rate=fs))\n",
    "    return out\n",
    "\n",
    "def frame_signal(x, frame_size, hop_size):\n",
    "    #Split signal into overlapping frames\n",
    "    num_frames = 1 + (len(x) - frame_size) // hop_size\n",
    "    frames = np.zeros((num_frames, frame_size))\n",
    "    for i in range(num_frames):\n",
    "        start = i * hop_size\n",
    "        frames[i] = x[start:start+frame_size]\n",
    "    return frames\n",
    "\n",
    "def zero_crossing_rate(frame):\n",
    "    return np.mean(np.abs(np.diff(np.sign(frame))))\n",
    "\n",
    "def autocorr_pitch(frame, fs, fmin=50, fmax=400): \n",
    "    # Autocorrelation method for pitch estimation\n",
    "    corr = np.correlate(frame, frame, mode='full')\n",
    "    corr = corr[len(corr)//2:]  # keep positive lags\n",
    "    min_lag = int(fs/fmax)\n",
    "    max_lag = int(fs/fmin)\n",
    "    lag = np.argmax(corr[min_lag:max_lag]) + min_lag\n",
    "    f0 = fs / lag\n",
    "    return f0\n",
    "\n",
    "def voiced_unvoiced(frame, energy_thresh=1e-3, zcr_thresh=0.1):\n",
    "    energy = np.sum(frame**2)\n",
    "    zcr = zero_crossing_rate(frame)\n",
    "    if energy > energy_thresh and zcr < zcr_thresh:\n",
    "        return \"voiced\"\n",
    "    else:\n",
    "        return \"unvoiced\"\n",
    "\n",
    "\n",
    "def generate_excitation(frame, fs):\n",
    "    vu = voiced_unvoiced(frame)\n",
    "    if vu == \"voiced\":\n",
    "        f0 = autocorr_pitch(frame, fs) # Estimate pitch for voiced frames\n",
    "        N = int(fs / f0)\n",
    "        excitation = np.zeros(len(frame))\n",
    "        excitation[::N] = 1.0\n",
    "    else:\n",
    "        excitation = np.random.randn(len(frame)) * 0.1 # Random noise for unvoiced frames\n",
    "    return excitation, vu\n",
    "\n",
    "def make_bands(fs,\n",
    "               n_bands=8,\n",
    "               fmin=200.0,\n",
    "               fmax=None,\n",
    "               log=True,\n",
    "               min_bandwidth_hz=1.0,\n",
    "               top_margin=0.999):\n",
    "    \"\"\"\n",
    "    Create n_bands frequency (low, high) tuples between fmin and fmax.\n",
    "\n",
    "    - top_margin: fraction of Nyquist to use as top cap (must be < 1.0).\n",
    "    - min_bandwidth_hz: enforce a tiny minimum bandwidth to avoid duplicates.\n",
    "    \"\"\"\n",
    "    if fmax is None:\n",
    "        fmax = fs / 2.0\n",
    "\n",
    "    # Safety clamps\n",
    "    nyq = fs / 2.0\n",
    "    if fmin <= 0:\n",
    "        raise ValueError(\"fmin must be > 0 Hz\")\n",
    "    if fmax <= fmin:\n",
    "        raise ValueError(\"fmax must be > fmin\")\n",
    "    # Ensure top edge is strictly below Nyquist\n",
    "    max_allowed = nyq * float(top_margin)\n",
    "    if fmax > max_allowed:\n",
    "        fmax = max_allowed\n",
    "\n",
    "    if log:\n",
    "        edges = np.logspace(np.log10(fmin), np.log10(fmax), n_bands + 1)\n",
    "    else:\n",
    "        edges = np.linspace(fmin, fmax, n_bands + 1)\n",
    "\n",
    "    bands = []\n",
    "    for i in range(n_bands):\n",
    "        low = float(edges[i])\n",
    "        high = float(edges[i + 1])\n",
    "        if high - low < min_bandwidth_hz:\n",
    "            # Expand tiny bands slightly to avoid degenerate filters\n",
    "            high = low + min_bandwidth_hz\n",
    "            if high > max_allowed:\n",
    "                high = max_allowed\n",
    "                low = high - min_bandwidth_hz\n",
    "        # final safety clamp\n",
    "        low = max(low, 1e-6)\n",
    "        high = min(high, max_allowed)\n",
    "        if low >= high:\n",
    "            raise ValueError(f\"Invalid band edges: low={low} >= high={high}\")\n",
    "        bands.append((low, high))\n",
    "    return bands\n",
    "\n",
    "\n",
    "def bandpass_filter(x, lowcut, highcut, fs, order=4, zero_phase=True):\n",
    "    \"\"\"\n",
    "    Stable bandpass using second-order-sections. Uses filtfilt for zero-phase if requested.\n",
    "    lowcut/highcut in Hz. Internally clamps to (0, Nyquist).\n",
    "    \"\"\"\n",
    "    nyq = fs / 2.0\n",
    "    # guard against accidental edges at/above Nyquist or <= 0\n",
    "    low = max(lowcut, 1e-6) / nyq\n",
    "    high = min(highcut, nyq * 0.999999) / nyq\n",
    "    if not (0.0 < low < high < 1.0):\n",
    "        raise ValueError(f\"Normalized band edges must satisfy 0 < low < high < 1, got low={low}, high={high}\")\n",
    "\n",
    "    # Use SOS for numerical stability\n",
    "    sos = butter(order, [low, high], btype='band', output='sos')\n",
    "    if zero_phase:\n",
    "        return sosfiltfilt(sos, x)\n",
    "    else:\n",
    "        return sosfilt(sos, x)\n",
    "\n",
    "def vocode(signal, fs, carrier=None, n_bands=4, frame_size=400, hop_size=160, log_bands=True):\n",
    "    # Determine output length\n",
    "    L_out = min(len(signal), len(carrier)) if carrier is not None else len(signal)\n",
    "    speech = signal[:L_out] / np.max(np.abs(signal[:L_out]))\n",
    "    frames = frame_signal(speech, frame_size=frame_size, hop_size=hop_size)\n",
    "    vu_mask = np.ones_like(speech)\n",
    "    \n",
    "    if carrier is not None:\n",
    "        # Voiced/unvoiced mask\n",
    "        for i, frame in enumerate(frames):\n",
    "            vu = voiced_unvoiced(frame)\n",
    "            start = i * hop_size\n",
    "            end = start + len(frame)\n",
    "            if vu == \"voiced\":\n",
    "                vu_mask[start:end] = 1.0  # pass voiced\n",
    "            else:\n",
    "                vu_mask[start:end] = 0.0  # silence unvoiced\n",
    "\n",
    "    # Generate carrier if not provided\n",
    "    if carrier is None:\n",
    "        carrier = np.zeros_like(speech)\n",
    "        for i, frame in enumerate(frames):\n",
    "            excitation, vu = generate_excitation(frame, fs)\n",
    "            start = i * hop_size\n",
    "            end = start + len(frame)\n",
    "            carrier[start:end] += excitation\n",
    "\n",
    "    # Make frequency bands\n",
    "    bands = make_bands(fs, n_bands=n_bands, fmin=200, fmax=fs/2, log=log_bands)\n",
    "    \n",
    "    out = np.zeros_like(speech)\n",
    "    for low, high in bands:\n",
    "        speech_band = bandpass_filter(speech, low, high, fs)\n",
    "        carrier_band = bandpass_filter(carrier[:L_out], low, high, fs)\n",
    "        env = envelope(speech_band)\n",
    "        \n",
    "        # Apply envelope to carrier and mask unvoiced if carrier was provided\n",
    "        L = min(len(speech_band), len(carrier_band), len(env))\n",
    "        modulated = carrier_band[:L] * env[:L]\n",
    "        if carrier is not None:\n",
    "            modulated *= vu_mask[:L]  # silence unvoiced segments\n",
    "        out[:L] += modulated\n",
    "\n",
    "    # Normalize output RMS\n",
    "    rms = np.sqrt(np.mean(out**2))\n",
    "    vocoder_out = out / rms if rms > 0 else out\n",
    "\n",
    "    return vocoder_out, carrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate first vocoder\n",
    "\n",
    "In this experiment, we construct a carrier signal that has an estimated $F_x$ for voiced portions of speech, and a hiss (white noise) for unvoiced segments. First, we use linearly spaced bands, which is what was initially used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play audio:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237e4589e13a42d8b4e91321bddb2414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Speech (source)'), Output(), Label(value='Carrier'), Output(), Label(value='4- ban…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the WAV file\n",
    "fs, speech = read(\"audio/The distant future.wav\") \n",
    "\n",
    "vocoder_out,  carrier = vocode(speech, fs, log_bands=False)\n",
    "vocoder_8band, carrier_8band = vocode(speech, fs, n_bands=8, log_bands=False) \n",
    "vocoder_20band, carrier_20band = vocode(speech, fs, n_bands=20, log_bands=False)\n",
    "vocoder_40band, carrier_40band = vocode(speech, fs, n_bands=40, log_bands=False)\n",
    "\n",
    "\n",
    "# --- Audio players ---\n",
    "print(\"Play audio:\")\n",
    "def audio_widget(data, fs):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "        display(Audio(data, rate=fs))\n",
    "    return out\n",
    "\n",
    "speech_w = audio_widget(speech, fs)\n",
    "carrier_w = audio_widget(carrier, fs)\n",
    "vocoder_w = audio_widget(vocoder_out, fs)\n",
    "vocoder8_w = audio_widget(vocoder_8band, fs)\n",
    "vocoder20_w = audio_widget(vocoder_20band, fs)\n",
    "vocoder40_w = audio_widget(vocoder_40band, fs)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Speech (source)\"), speech_w,\n",
    "    widgets.Label(\"Carrier\"), carrier_w,\n",
    "    widgets.Label(\"4- band Vocoder output\"), vocoder_w,\n",
    "    widgets.Label(\"8-band Vocoder output\"), vocoder8_w,\n",
    "    widgets.Label(\"20-band Vocoder output\"), vocoder20_w,\n",
    "    widgets.Label(\"40-band Vocoder output\"), vocoder40_w,\n",
    "])\n",
    "\n",
    "display(ui)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hear the difference when we use frequency bands separated at a log-scale (which is closer to the way our ear perceives sound):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play audio:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59c090f3f1842948fb67d67c48ffde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Speech (source)'), Output(), Label(value='Carrier'), Output(), Label(value='4- ban…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the WAV file\n",
    "fs, speech = read(\"audio/The distant future.wav\") \n",
    "\n",
    "vocoder_out,  carrier = vocode(speech, fs)\n",
    "vocoder_8band, carrier_8band = vocode(speech, fs, n_bands=8) \n",
    "vocoder_20band, carrier_20band = vocode(speech, fs, n_bands=20)\n",
    "vocoder_40band, carrier_40band = vocode(speech, fs, n_bands=40)\n",
    "\n",
    "\n",
    "# --- Audio players ---\n",
    "print(\"Play audio:\")\n",
    "def audio_widget(data, fs):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "        display(Audio(data, rate=fs))\n",
    "    return out\n",
    "\n",
    "speech_w = audio_widget(speech, fs)\n",
    "carrier_w = audio_widget(carrier, fs)\n",
    "vocoder_w = audio_widget(vocoder_out, fs)\n",
    "vocoder8_w = audio_widget(vocoder_8band, fs)\n",
    "vocoder20_w = audio_widget(vocoder_20band, fs)\n",
    "vocoder40_w = audio_widget(vocoder_40band, fs)\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Speech (source)\"), speech_w,\n",
    "    widgets.Label(\"Carrier\"), carrier_w,\n",
    "    widgets.Label(\"4- band Vocoder output\"), vocoder_w,\n",
    "    widgets.Label(\"8-band Vocoder output\"), vocoder8_w,\n",
    "    widgets.Label(\"20-band Vocoder output\"), vocoder20_w,\n",
    "    widgets.Label(\"40-band Vocoder output\"), vocoder40_w,\n",
    "])\n",
    "\n",
    "display(ui)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocoding a basic synth chord progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Basic synth functions ---\n",
    "def midi_to_freq(midi_note):\n",
    "    \"\"\"Convert MIDI note number to frequency in Hz.\"\"\"\n",
    "    return 440.0 * (2.0 ** ((midi_note - 69) / 12.0))\n",
    "\n",
    "def saw_wave(freq, duration, fs):\n",
    "    \"\"\"Generate a sawtooth wave for a given frequency and duration.\"\"\"\n",
    "    t = np.linspace(0, duration, int(fs*duration), endpoint=False)\n",
    "    return 2 * (t*freq - np.floor(0.5 + t*freq))\n",
    "\n",
    "def chord_wave(notes, duration, fs):\n",
    "    \"\"\"Generate a chord (sum of saw waves).\"\"\"\n",
    "    waves = [saw_wave(midi_to_freq(n), duration, fs) for n in notes]\n",
    "    return np.sum(waves, axis=0) / len(waves)\n",
    "\n",
    "def match_rms(x, target_rms):\n",
    "    return x * (target_rms / (np.sqrt(np.mean(x**2)) + 1e-9))\n",
    "\n",
    "# --- Define some MIDI chords ---\n",
    "fs = 16000\n",
    "chords = {\n",
    "    \"C\" : [60, 64, 67],   # C major\n",
    "    \"Am\": [69, 72, 76],   # A minor\n",
    "    \"G7\" : [55, 59, 62, 66],   # G major 7\n",
    "}\n",
    "\n",
    "# --- Synthesize and vocode each chord ---\n",
    "fs, speech = read(\"audio/What did you say.wav\") \n",
    "\n",
    "notes = [(\"C\", 2.4), (\"Am\", 1.0), (\"G7\", 1.0)]\n",
    "synth_audio = np.concatenate([chord_wave(chords[name], dur, fs) for name, dur in notes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Play audio:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bf1b918f2c488babeea2fae00f2ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Speech (source)'), Output(), Label(value='Carrier (Synth chords)'), Output(), Labe…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "vocoder_out,  _ = vocode(speech, fs, carrier=synth_audio)\n",
    "vocoder_8band, _ = vocode(speech, fs, carrier=synth_audio, n_bands=8) \n",
    "vocoder_20band, _ = vocode(speech, fs, carrier=synth_audio, n_bands=20)\n",
    "vocoder_40band, _ = vocode(speech, fs, carrier=synth_audio, n_bands=40)\n",
    "vocoder_100band, _ = vocode(speech, fs, carrier=synth_audio, n_bands=100)\n",
    "\n",
    "\n",
    "# --- Corrected Audio Combination ---\n",
    "L = min(len(speech), len(vocoder_40band))\n",
    "\n",
    "speech_norm = speech[:L] / np.max(np.abs(speech[:L]) + 1e-9)\n",
    "vocoder_norm = vocoder_40band[:L] / np.max(np.abs(vocoder_20band[:L]) + 1e-9)\n",
    "\n",
    "mix_ratio_speech = 0.45  # Controls how much of the original speech you hear\n",
    "mix_ratio_vocoder = 1 - mix_ratio_speech # Controls how much of the vocoded effect you hear\n",
    "\n",
    "combined = (speech_norm * mix_ratio_speech) + (vocoder_norm * mix_ratio_vocoder)\n",
    "\n",
    "# 3. Final normalization to prevent clipping and set a good playback level\n",
    "combined /= np.max(np.abs(combined) + 1e-9)\n",
    "\n",
    "# --- Audio players ---\n",
    "print(\"Play audio:\")\n",
    "def audio_widget(data, fs):\n",
    "    out = widgets.Output()\n",
    "    with out:\n",
    "        display(Audio(data, rate=fs))\n",
    "    return out\n",
    "\n",
    "speech_w = audio_widget(speech, fs)\n",
    "carrier_w = audio_widget(synth_audio, fs)\n",
    "vocoder_w = audio_widget(vocoder_out, fs)\n",
    "vocoder8_w = audio_widget(vocoder_8band, fs)\n",
    "vocoder20_w = audio_widget(vocoder_20band, fs)\n",
    "vocoder40_w = audio_widget(vocoder_40band, fs)\n",
    "vocoder100_w = audio_widget(vocoder_100band, fs)\n",
    "combined_w = audio_widget(combined, fs)\n",
    "\n",
    "\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Speech (source)\"), speech_w,\n",
    "    widgets.Label(\"Carrier (Synth chords)\"), carrier_w,\n",
    "    widgets.Label(\"4- band Vocoder output\"), vocoder_w,\n",
    "    widgets.Label(\"8-band Vocoder output\"), vocoder8_w,\n",
    "    widgets.Label(\"20-band Vocoder output\"), vocoder20_w,\n",
    "    widgets.Label(\"40-band Vocoder output\"), vocoder40_w,\n",
    "    widgets.Label(\"100-band Vocoder output\"), vocoder100_w,\n",
    "    widgets.Label(\"Combined original + 20-band vocoder\"), combined_w,\n",
    "])\n",
    "\n",
    "display(ui)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
